import streamlit as st
import pandas as pd
import openai
import faiss
import numpy as np

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ Ù†ØµÙˆØµ Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ©", layout="wide")
st.title("ğŸ“š Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ Ù†ØµÙˆØµ Ø´ÙŠØ® Ø§Ù„Ø¥Ø³Ù„Ø§Ù… Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ©")

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
openai_key = st.sidebar.text_input("ğŸ” Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI", type="password")

model_choice = st.sidebar.selectbox(
    "ğŸ¤– Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ OpenAI",
    options=["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
    index=0
)

threshold = st.sidebar.slider(
    "ğŸšï¸ Ø­Ø¯ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ù‚ØµÙˆÙ‰ (ÙƒÙ„Ù…Ø§ Ù‚Ù„Ù‘ Ø§Ù„Ø±Ù‚Ù… Ø²Ø§Ø¯Øª Ø§Ù„Ø¯Ù‚Ø©)",
    min_value=0.1,
    max_value=1.0,
    value=0.35,
    step=0.05
)

embedding_model = "text-embedding-ada-002"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
@st.cache_resource
def load_data():
    df = pd.read_csv("dar1_with_embeddings001.csv")
    index = faiss.read_index("faiss_dar1001.index")
    return df, index

df, index = load_data()

# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ embedding
def get_embedding(text):
    from openai import OpenAI
    client = OpenAI(api_key=openai_key)
    response = client.embeddings.create(
        input=[text.replace("\n", " ")],
        model=embedding_model
    )
    return response.data[0].embedding

# Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù…Ø¹ ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
def search_semantic(query, top_k=10, threshold=0.35):
    query_vec = np.array(get_embedding(query)).astype("float32").reshape(1, -1)
    distances, indices = index.search(query_vec, top_k)

    results = []
    for i, dist in enumerate(distances[0]):
        if dist < threshold:
            match = df.iloc[indices[0][i]]
            results.append((match, dist))

    return results

# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø´Ø±Ø­ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
def explain_match(query, match_text):
    prompt = f"""Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "{query}"
Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„Ø§Ù… Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ©: "{match_text}"

Ø§Ø´Ø±Ø­ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù„ØºØ© Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ø¶Ø­Ø©:"""

    from openai import OpenAI
    client = OpenAI(api_key=openai_key)
    response = client.chat.completions.create(
        model=model_choice,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„
query = st.text_input("ğŸ“ Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ", placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù…ÙˆÙ‚Ù Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ© Ù…Ù† ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¹Ù‚Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ù„ØŸ")

if query and openai_key:
    with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
        results = search_semantic(query, top_k=10, threshold=threshold)

        if not results:
            st.warning("â— Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ Ù‚Ø±ÙŠØ¨ Ø¨Ù…Ø§ ÙŠÙƒÙÙŠ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
        else:
            for i, (row, dist) in enumerate(results):
                st.markdown(f"### ğŸ”¹ Ø§Ù„Ù†Øµ {i+1} (Ø§Ù„Ù…Ø³Ø§ÙØ©: {dist:.3f})")
                st.write(row['text'])

                with st.expander("ğŸ§  ØªÙØ³ÙŠØ± Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©"):
                    explanation = explain_match(query, row['text'])
                    st.write(explanation)
